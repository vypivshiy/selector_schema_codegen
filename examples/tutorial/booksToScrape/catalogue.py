# autogenerated by ssc-gen DO NOT_EDIT

import re
from typing import List, TypedDict, Union, Optional
from contextlib import suppress
from functools import reduce


from bs4 import BeautifulSoup, ResultSet, Tag  # noqa (for typing)

T_Book = TypedDict(
    "T_Book",
    {
        "name": str,
        "image_url": str,
        "url": str,
        "rating": int,
        "price": float,
    },
)
T_MainCatalogue = TypedDict(
    "T_MainCatalogue",
    {
        "books": List[T_Book],
        "prev_page": Optional[str],
        "next_page": Optional[str],
        "curr_page": str,
    },
)


class Book:
    """Exctract a book cards

        Usage:

            - GET https://books.toscrape.com/
            - GET https://books.toscrape.com/catalogue/page-2.html
            - GET https://books.toscrape.com/catalogue/page-50.html


    [
        {
            "name": "String",
            "image_url": "String",
            "url": "String",
            "rating": "Int",
            "price": "Float"
        },
        "..."
    ]"""

    def __init__(self, document: Union[bytes, str, BeautifulSoup, Tag]) -> None:
        self._document = (
            BeautifulSoup(document, "lxml")
            if isinstance(document, (str, bytes))
            else document
        )

    def _pre_validate(self, v: Union[BeautifulSoup, Tag]) -> None:
        assert v.select_one(".col-lg-3 .thumbnail"), ""
        return

    def _split_doc(self, v: Union[BeautifulSoup, Tag]) -> ResultSet:
        
        return v.select(".col-lg-3")

    def _parse_name(self, v: Union[BeautifulSoup, Tag]) -> str:
        v0 = v.select_one(".thumbnail")
        
        return " ".join(v0.get_attribute_list("alt"))

    def _parse_image_url(self, v: Union[BeautifulSoup, Tag]) -> str:
        v0 = v.select_one(".thumbnail")
        v1 = " ".join(v0.get_attribute_list("src"))
        v2 = v1[len("..") :] if v1.startswith("..") else v1
        v3 = v2.lstrip("/")
        
        return f"https://books.toscrape.com/{v3}"

    def _parse_url(self, v: Union[BeautifulSoup, Tag]) -> str:
        v0 = v.select_one(".image_container > a")
        v1 = " ".join(v0.get_attribute_list("href"))
        v2 = v1.lstrip("/")
        v3 = v2[len("catalogue/") :] if v2.startswith("catalogue/") else v2
        
        return f"https://books.toscrape.com/catalogue/{v3}"

    def _parse_rating(self, v: Union[BeautifulSoup, Tag]) -> int:
        v0 = v
        with suppress(Exception):
            v1 = v0.select_one(".star-rating")
            v2 = " ".join(v1.get_attribute_list("class"))
            v3 = (
                v2[len("star-rating ") :]
                if v2.startswith("star-rating ")
                else v2
            )
            v4 = reduce(
                lambda acc, kv: acc.replace(kv[0], kv[1]),
                {
                    "One": "1",
                    "Two": "2",
                    "Three": "3",
                    "Four": "4",
                    "Five": "5",
                }.items(),
                v3,
            )
            
            return int(v4)
        return 0

    def _parse_price(self, v: Union[BeautifulSoup, Tag]) -> float:
        v0 = v
        with suppress(Exception):
            v1 = v0.select_one(".price_color")
            v2 = v1.text
            v3 = re.search("(\\d+(?:.\\d+)?)", v2)[1]
            
            return float(v3)
        return 0.0

    def parse(self) -> List[T_Book]:
        self._pre_validate(self._document)
        return [
            {
                "name": self._parse_name(el),
                "image_url": self._parse_image_url(el),
                "url": self._parse_url(el),
                "rating": self._parse_rating(el),
                "price": self._parse_price(el),
            }
            for el in self._split_doc(self._document)
        ]


class MainCatalogue:
    """Extract pagination urls and book cards

        Usage Examples:

            - GET https://books.toscrape.com/
            - GET https://books.toscrape.com/catalogue/page-2.html
            - GET https://books.toscrape.com/catalogue/page-50.html

        Issues:
            - on the first page, prev_page = None
            - on the last page, next_page = None


    {
        "books": [
            {
                "name": "String",
                "image_url": "String",
                "url": "String",
                "rating": "Int",
                "price": "Float"
            },
            "..."
        ],
        "prev_page": "String",
        "next_page": "String",
        "curr_page": "String"
    }"""

    def __init__(self, document: Union[bytes, str, BeautifulSoup, Tag]) -> None:
        self._document = (
            BeautifulSoup(document, "lxml")
            if isinstance(document, (str, bytes))
            else document
        )

    def _parse_books(self, v: Union[BeautifulSoup, Tag]) -> List[T_Book]:
        
        return Book(v).parse()

    def _parse_prev_page(self, v: Union[BeautifulSoup, Tag]) -> Optional[str]:
        v0 = v
        with suppress(Exception):
            v1 = v0.select_one(".previous a")
            v2 = " ".join(v1.get_attribute_list("href"))
            v3 = v2[len("catalogue/") :] if v2.startswith("catalogue/") else v2
            
            return f"https://books.toscrape.com/catalogue/{v3}"
        return None

    def _parse_next_page(self, v: Union[BeautifulSoup, Tag]) -> Optional[str]:
        v0 = v
        with suppress(Exception):
            v1 = v0.select_one(".next a")
            v2 = " ".join(v1.get_attribute_list("href"))
            v3 = v2[len("catalogue/") :] if v2.startswith("catalogue/") else v2
            
            return f"https://books.toscrape.com/catalogue/{v3}"
        return None

    def _parse_curr_page(self, v: Union[BeautifulSoup, Tag]) -> str:
        v0 = v.select_one(".current")
        v1 = v0.text
        v2 = re.search("Page\\s(\\d+)", v1)[1]
        
        return f"https://books.toscrape.com/catalogue/page-{v2}.html"

    def parse(self) -> T_MainCatalogue:
        return {
            "books": self._parse_books(self._document),
            "prev_page": self._parse_prev_page(self._document),
            "next_page": self._parse_next_page(self._document),
            "curr_page": self._parse_curr_page(self._document),
        }
