# Syntax

## DSL Concept

This DSL is designed to maximize declarative unification and standardization of code for web-scraping tasks.

- Design is inspired by the libraries for serialization/deserialization and ORM
- Transfers the documentation: with the help of it, you can tell what it is for, how to prepare an http response, what errors can occur
- transpiles a single, independent module, it can be reused in any projects and tasks!
- Generates signatures in the documentation. If possible, also types/structures
- Based python syntax, the IDE auto-complete significantly speeds up prototyping and parsers development

## quickstart

create config:

```python
""" main docstring example
ssc-gen transpiles it at the beginning of the file
"""
from ssc_codegen import ItemSchema, D, N


class Contacts(ItemSchema):
    """Simple extract contacts from page by a[href] attribute. If field not founded - return None

    See also:
        https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/a#href
    """
    # Tip: To write efficient selectors and improve performance, it's recommended to learn CSS3 standard selectors:
    # https://www.w3schools.com/cssref/css_selectors.php
    # Helpful browser extensions:
    # SelectorGadget (Chrome)
    # ScrapeMate (Firefox)

    # NOTE:
    # [attribute^="value"] selector matches elements whose attribute value starts with a given string.
    # If an element is not found, the eval field will use a default fallback value.
    phone = D(default=None).css('a[href^="tel:"]').attr("href")
    # this alias shortcut
    email = D(None).css('a[href^="email:"]').attr("href")


class HelloWorld(ItemSchema):
    # Web-scraping involves the use of undocumented methods and selectors.
    # So in some cases it is recommended to document what needs to be
    # submitted for input and what problems may occur
    """Example demonstration documentation schema usage.

    Usage:

        GET any html page

    Issues:

        If <a> tags in target page not exists, it throw error!
    """
    title = D().css('title').text()
    a_hrefs = D().css_all('a').attr('href')
    contacts = N().sub_parser(Contacts)
```

Transpile this DSL to real code


### python

bs4

> ssc-gen py -i bs4  ssc_configs/schema.py -o . -p bs4_
```python
# autogenerated by ssc-gen DO NOT_EDIT
"""main docstring example
ssc-gen transpiles it at the beginning of the file
"""

import re
from html import unescape as _html_unescape
from typing import List, Dict, TypedDict, Union, Optional
from contextlib import suppress
from functools import reduce


from bs4 import BeautifulSoup, ResultSet, Tag  # noqa (for typing)


_RE_HEX_ENTITY = re.compile(r"&#x([0-9a-fA-F]+);")
_RE_UNICODE_ENTITY = re.compile(r"\\\\u([0-9a-fA-F]{4})")
_RE_BYTES_ENTITY = re.compile(r"\\\\x([0-9a-fA-F]{2})")
_RE_CHARS_MAP = {
    "\\b": "\b",
    "\\f": "\f",
    "\\n": "\n",
    "\\r": "\r",
    "\\t": "\t",
}


def ssc_unescape(s: str) -> str:
    s = _html_unescape(s)
    s = _RE_HEX_ENTITY.sub(lambda m: chr(int(m.group(1), 16)), s)
    s = _RE_UNICODE_ENTITY.sub(lambda m: chr(int(m.group(1), 16)), s)
    s = _RE_BYTES_ENTITY.sub(lambda m: chr(int(m.group(1), 16)), s)
    
    return (
        s.replace("\\b", "\b")
        .replace("\\f", "\f")
        .replace("\\n", "\n")
        .replace("\\t", "\t")
    )


def ssc_map_replace(s: str, replacements: Dict[str, str]) -> str:
    return reduce(
        lambda acc, kv: acc.replace(kv[0], kv[1]), replacements.items(), s
    )


def ssc_rm_prefix(v: str, p: str) -> str:
    return v[len(p) :] if v.startswith(p) else v


def ssc_rm_suffix(v: str, s: str) -> str:
    return v[: -(len(s))] if v.endswith(s) else v


def ssc_rm_prefix_and_suffix(v: str, p: str, s: str) -> str:
    return ssc_rm_suffix(ssc_rm_prefix(v, p), s)


T_Contacts = TypedDict(
    "T_Contacts",
    {
        "phone": Optional[str],
        "email": Optional[str],
    },
)
T_HelloWorld = TypedDict(
    "T_HelloWorld",
    {
        "title": str,
        "a_hrefs": List[str],
        "contacts": T_Contacts,
    },
)


class Contacts:
    """Simple extract contacts from page by a[href] attribute. If field not founded - return None

        See also:
            https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/a#href


    {
        "phone": "String",
        "email": "String"
    }"""

    def __init__(self, document: Union[bytes, str, BeautifulSoup, Tag]) -> None:
        self._document = (
            BeautifulSoup(document, "lxml")
            if isinstance(document, (str, bytes))
            else document
        )

    def _parse_phone(self, v: Union[BeautifulSoup, Tag]) -> Optional[str]:
        v0 = v
        with suppress(Exception):
            v1 = v0.select_one('a[href^="tel:"]')
            
            return " ".join(v1.get_attribute_list("href"))
        return None

    def _parse_email(self, v: Union[BeautifulSoup, Tag]) -> Optional[str]:
        v0 = v
        with suppress(Exception):
            v1 = v0.select_one('a[href^="email:"]')
            
            return " ".join(v1.get_attribute_list("href"))
        return None

    def parse(self) -> T_Contacts:
        return {
            "phone": self._parse_phone(self._document),
            "email": self._parse_email(self._document),
        }


class HelloWorld:
    """Example demonstration documentation schema usage.

        Usage:

            GET any html page

        Issues:

            If <a> tags in target page not exists, it throw error!


    {
        "title": "String",
        "a_hrefs": "Array<String>",
        "contacts": {
            "phone": "String | null",
            "email": "String | null"
        }
    }"""

    def __init__(self, document: Union[bytes, str, BeautifulSoup, Tag]) -> None:
        self._document = (
            BeautifulSoup(document, "lxml")
            if isinstance(document, (str, bytes))
            else document
        )

    def _parse_title(self, v: Union[BeautifulSoup, Tag]) -> str:
        v0 = v.select_one("title")
        
        return v0.text

    def _parse_a_hrefs(self, v: Union[BeautifulSoup, Tag]) -> List[str]:
        v0 = v.select("a")
        
        return [
            " ".join(e.get_attribute_list("href")) for e in v0 if e.get("href")
        ]

    def _parse_contacts(self, v: Union[BeautifulSoup, Tag]) -> T_Contacts:
        
        return Contacts(v).parse()

    def parse(self) -> T_HelloWorld:
        return {
            "title": self._parse_title(self._document),
            "a_hrefs": self._parse_a_hrefs(self._document),
            "contacts": self._parse_contacts(self._document),
        }
```

selectolax 

> ssc-gen py -i selectolax  ssc_configs/schema.py -o . -p slax_
```python
# autogenerated by ssc-gen DO NOT_EDIT
"""main docstring example
ssc-gen transpiles it at the beginning of the file
"""

import re
from html import unescape as _html_unescape
from typing import List, Dict, TypedDict, Union, Optional
from contextlib import suppress
from functools import reduce


from selectolax.lexbor import LexborHTMLParser as HTMLParser, LexborNode as Node


_RE_HEX_ENTITY = re.compile(r"&#x([0-9a-fA-F]+);")
_RE_UNICODE_ENTITY = re.compile(r"\\\\u([0-9a-fA-F]{4})")
_RE_BYTES_ENTITY = re.compile(r"\\\\x([0-9a-fA-F]{2})")
_RE_CHARS_MAP = {
    "\\b": "\b",
    "\\f": "\f",
    "\\n": "\n",
    "\\r": "\r",
    "\\t": "\t",
}


def ssc_unescape(s: str) -> str:
    s = _html_unescape(s)
    s = _RE_HEX_ENTITY.sub(lambda m: chr(int(m.group(1), 16)), s)
    s = _RE_UNICODE_ENTITY.sub(lambda m: chr(int(m.group(1), 16)), s)
    s = _RE_BYTES_ENTITY.sub(lambda m: chr(int(m.group(1), 16)), s)
    
    return (
        s.replace("\\b", "\b")
        .replace("\\f", "\f")
        .replace("\\n", "\n")
        .replace("\\t", "\t")
    )


def ssc_map_replace(s: str, replacements: Dict[str, str]) -> str:
    return reduce(
        lambda acc, kv: acc.replace(kv[0], kv[1]), replacements.items(), s
    )


def ssc_rm_prefix(v: str, p: str) -> str:
    return v[len(p) :] if v.startswith(p) else v


def ssc_rm_suffix(v: str, s: str) -> str:
    return v[: -(len(s))] if v.endswith(s) else v


def ssc_rm_prefix_and_suffix(v: str, p: str, s: str) -> str:
    return ssc_rm_suffix(ssc_rm_prefix(v, p), s)


T_Contacts = TypedDict(
    "T_Contacts",
    {
        "phone": Optional[str],
        "email": Optional[str],
    },
)
T_HelloWorld = TypedDict(
    "T_HelloWorld",
    {
        "title": str,
        "a_hrefs": List[str],
        "contacts": T_Contacts,
    },
)


class Contacts:
    """Simple extract contacts from page by a[href] attribute. If field not founded - return None

        See also:
            https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/a#href


    {
        "phone": "String",
        "email": "String"
    }"""

    def __init__(self, document: Union[str, HTMLParser, Node]) -> None:
        self._document = (
            HTMLParser(document) if isinstance(document, str) else document
        )

    def _parse_phone(self, v: Union[HTMLParser, Node]) -> Optional[str]:
        v0 = v
        with suppress(Exception):
            v1 = v0.css_first('a[href^="tel:"]')
            
            return v1.attributes["href"]
        return None

    def _parse_email(self, v: Union[HTMLParser, Node]) -> Optional[str]:
        v0 = v
        with suppress(Exception):
            v1 = v0.css_first('a[href^="email:"]')
            
            return v1.attributes["href"]
        return None

    def parse(self) -> T_Contacts:
        return {
            "phone": self._parse_phone(self._document),
            "email": self._parse_email(self._document),
        }


class HelloWorld:
    """Example demonstration documentation schema usage.

        Usage:

            GET any html page

        Issues:

            If <a> tags in target page not exists, it throw error!


    {
        "title": "String",
        "a_hrefs": "Array<String>",
        "contacts": {
            "phone": "String | null",
            "email": "String | null"
        }
    }"""

    def __init__(self, document: Union[str, HTMLParser, Node]) -> None:
        self._document = (
            HTMLParser(document) if isinstance(document, str) else document
        )

    def _parse_title(self, v: Union[HTMLParser, Node]) -> str:
        v0 = v.css_first("title")
        
        return v0.text()

    def _parse_a_hrefs(self, v: Union[HTMLParser, Node]) -> List[str]:
        v0 = v.css("a")
        
        return [e.attributes["href"] for e in v0]

    def _parse_contacts(self, v: Union[HTMLParser, Node]) -> T_Contacts:
        
        return Contacts(v).parse()

    def parse(self) -> T_HelloWorld:
        return {
            "title": self._parse_title(self._document),
            "a_hrefs": self._parse_a_hrefs(self._document),
            "contacts": self._parse_contacts(self._document),
        }
```

### js

> ssc-gen js ssc_configs/schema.py -o .
```javascript
// autogenerated by ssc-gen DO NOT_EDIT
/***  main docstring example
 * ssc-gen transpiles it at the beginning of the file
 * */

function sscRmPrefix(v, p) {
    return v.startsWith(p) ? v.slice(p.length) : v;
}

function sscRmSuffix(v, s) {
    return v.endsWith(s) ? v.slice(0, -s.length) : v;
}

function sscRmPrefixSuffix(v, p, s) {
    return sscRmSuffix(sscRmPrefix(v, p), s);
}

/*** Simple extract contacts from page by a[href] attribute. If field not founded - return None
 *
 *     See also:
 *         https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/a#href
 *
 *
 * {
 *     "phone": "String",
 *     "email": "String"
 * }*/
class Contacts {
    constructor(doc) {
        if (typeof doc === 'string') {
            this._doc = new DOMParser().parseFromString(doc, 'text/html');
        } else if (doc instanceof Document || doc instanceof Element) {
            this._doc = doc.cloneNode(true);
        } else {
            throw new Error(
                'Invalid input: Expected a Document, Element, or string',
            );
        }
    }

    _parsePhone(v) {
        let v0 = v;
        try {
            let v1 = v0.querySelector('a[href^="tel:"]');

            return v1.getAttribute('href');
        } catch (Error) {
            return null;
        }
    }
    _parseEmail(v) {
        let v0 = v;
        try {
            let v1 = v0.querySelector('a[href^="email:"]');

            return v1.getAttribute('href');
        } catch (Error) {
            return null;
        }
    }
    parse() {
        return {
            phone: this._parsePhone(this._doc),

            email: this._parseEmail(this._doc),
        };
    }
}
/*** Example demonstration documentation schema usage.
 *
 *     Usage:
 *
 *         GET any html page
 *
 *     Issues:
 *
 *         If <a> tags in target page not exists, it throw error!
 *
 *
 * {
 *     "title": "String",
 *     "a_hrefs": "Array<String>",
 *     "contacts": {
 *         "phone": "String | null",
 *         "email": "String | null"
 *     }
 * }*/
class HelloWorld {
    constructor(doc) {
        if (typeof doc === 'string') {
            this._doc = new DOMParser().parseFromString(doc, 'text/html');
        } else if (doc instanceof Document || doc instanceof Element) {
            this._doc = doc.cloneNode(true);
        } else {
            throw new Error(
                'Invalid input: Expected a Document, Element, or string',
            );
        }
    }

    _parseTitle(v) {
        let v0 = v.querySelector('title');

        return typeof v0.textContent === 'undefined'
            ? v0.documentElement.textContent
            : v0.textContent;
    }
    _parseAHrefs(v) {
        let v0 = Array.from(v.querySelectorAll('a'));

        return v0.map((e) => e.getAttribute('href'));
    }
    _parseContacts(v) {
        return new Contacts(v).parse();
    }
    parse() {
        return {
            title: this._parseTitle(this._doc),

            a_hrefs: this._parseAHrefs(this._doc),

            contacts: this._parseContacts(this._doc),
        };
    }
}
```

### golang

> ssc-gen go ssc_configs/schema.py -o .
```go
// autogenerated by ssc-gen DO NOT_EDIT
//  main docstring example
// ssc-gen transpiles it at the beginning of the file
//

package main

import (
	"fmt"

	"github.com/PuerkitoBio/goquery"
)

// NOTE:
// MOST unused helper functions will be removed for decrease source view
func sscGetAttr(a *goquery.Selection, key string) (string, error) {
	if attr, ok := a.Attr(key); ok {
		return attr, nil
	}
	return "", fmt.Errorf("attr `%s` not exists", key)
}

func sscEachGetAttrs(a *goquery.Selection, key string) ([]string, error) {
	var r []string
	var err error
	a.Each(func(_ int, s *goquery.Selection) {
		if attr, ok := s.Attr(key); ok {
			r = append(r, attr)
		} else if err == nil {
			err = fmt.Errorf("attr `%s` not exists", key)
		}
	})
	return r, err
}


type TContacts struct {
	Phone *string `json:"phone"`
	Email *string `json:"email"`
}
type THelloWorld struct {
	Title    string    `json:"title"`
	AHrefs   []string  `json:"a_hrefs"`
	Contacts TContacts `json:"contacts"`
}

// Contacts Simple extract contacts from page by a[href] attribute. If field not founded - return None
//
//	See also:
//	    https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/a#href
//
//	{
//	    "phone": "String",
//	    "email": "String"
//	}
type Contacts struct {
	Document *goquery.Document
}

func (p *Contacts) parsePhone(v *goquery.Selection) (result *string, err error) {
	defer func() {
		if r := recover(); r != nil {
			err = nil
			result = nil
		}
	}()
	v0 := v
	v1 := v0.Find("a[href^=\"tel:\"]").First()
	v2, err := sscGetAttr(v1, "href")
	if err != nil {
		panic(err)
	}
	result = &v2
	return result, nil
}
func (p *Contacts) parseEmail(v *goquery.Selection) (result *string, err error) {
	defer func() {
		if r := recover(); r != nil {
			err = nil
			result = nil
		}
	}()
	v0 := v
	v1 := v0.Find("a[href^=\"email:\"]").First()
	v2, err := sscGetAttr(v1, "href")
	if err != nil {
		panic(err)
	}
	result = &v2
	return result, nil
}
func (p *Contacts) Parse() (*TContacts, error) {

	phone, err := p.parsePhone(p.Document.Selection)
	if err != nil {
		return nil, err
	}
	email, err := p.parseEmail(p.Document.Selection)
	if err != nil {
		return nil, err
	}

	item := TContacts{
		phone, email,
	}
	return &item, nil
}

// HelloWorld Example demonstration documentation schema usage.
//
//	Usage:
//
//	    GET any html page
//
//	Issues:
//
//	    If <a> tags in target page not exists, it throw error!
//
//	{
//	    "title": "String",
//	    "a_hrefs": "Array<String>",
//	    "contacts": {
//	        "phone": "String | null",
//	        "email": "String | null"
//	    }
//	}
type HelloWorld struct {
	Document *goquery.Document
}

func (p *HelloWorld) parseTitle(v *goquery.Selection) (string, error) {
	v0 := v.Find("title").First()
	v1 := v0.Text()
	return v1, nil
}
func (p *HelloWorld) parseAHrefs(v *goquery.Selection) ([]string, error) {
	v0 := v.Find("a")
	v1, err := sscEachGetAttrs(v0, "href")
	if err != nil {
		return nil, err
	}
	return v1, nil
}
func (p *HelloWorld) parseContacts(v *goquery.Selection) (*TContacts, error) {
	v0Doc := goquery.NewDocumentFromNode(v.Nodes[0])
	v0St := Contacts{v0Doc}
	v0, err := v0St.Parse()
	if err != nil {
		return nil, err
	}
	return v0, nil
}
func (p *HelloWorld) Parse() (*THelloWorld, error) {

	title, err := p.parseTitle(p.Document.Selection)
	if err != nil {
		return nil, err
	}
	aHrefs, err := p.parseAHrefs(p.Document.Selection)
	if err != nil {
		return nil, err
	}
	contacts, err := p.parseContacts(p.Document.Selection)
	if err != nil {
		return nil, err
	}

	item := THelloWorld{
		title, aHrefs, *contacts,
	}
	return &item, nil
}
```


## quick reference

## Schemas

Schema - special template structures that specify the behavior of how to collect data.

### Fields

To designate fields in structures, special fields are used:

```python
from ssc_codegen import D, R, N, F

# base field marker
D()
# for nested shemas
N()
# alias D().raw()
D().raw() == R()

# for filter expr
F()
```

### ItemSchema

Create a single map structure:

```python
from ssc_codegen import ItemSchema, D, R

class Main(ItemSchema):
    title = D().css("title::text")
    foo = R().re(r"(\d+)").to_int()
    bar = D().css_all("p::text")
```

generated parser code returns object: `{"title": str, "foo": int, "bar": list[str]}`

### ListSchema

create sequence of map structures:

```python
from ssc_codegen import ListSchema, D


class Main(ListSchema):
    # REQUIRED:
    # schema how to split document to elements:
    # eg schema input signature:
    # <body>
    # <div class="product_card">...</div>
    # <div class="product_card">...</div>
    # ...

    # extract all elements, where class="product card"
    # should be retuns LIST_DOCUMENT (end expr css_all or xpath_all)
    __SPLIT_DOC__ = D().css_all(".product_card")

    # parse every element from `__SPLIT_DOC__` result
    url = D().css("a::attr(href)")
    name = D().css(".product_name::text")
    price = D().css("div.price::text").to_float()
```

generated parser code returns object: `[{"name": str, "url": str, "price": float}, ...]`

### DictSchema

Сreate sequence of map structure with generic key name:

`{"__KEY__str1": __VALUE__1, ...}`

```python
from ssc_codegen import DictSchema, D


class Main(DictSchema):
    __SPLIT_DOC__ = D().css_all(".product_card")

    # __KEY__ always should be STRING type
    __KEY__ = D().css(".product_name::text")
    __VALUE__ = D().css("a::attr(href)")
```

### FlatListSchema

Сreate sequence of items

`[item_1, item_2, ...]`

```python
from ssc_codegen import FlatListSchema, D


class Main(FlatListSchema):
    __SPLIT_DOC__ = D().css_all(".product_card")

    __ITEM__ = D().css(".product_name::text")
```

### AccUniqueListSchema

Create sequence of unique items

- Every field should be returns LIST_STRING type
- After parse every fields - drop duplicates
- Order of elements will not be guaranteed

`[item_str_1, item_str_2, ...]`

```python
from ssc_codegen import AccUniqueListSchema, D


class Main(AccUniqueListSchema):
    # TIP: set default value as empty array:
    # if elements not be founded, returns empty sequence
    tiktok = D([]).css_all('a[href*="tiktok.com/"]::attr(href)')
    youtube = D([]).css_all('a[href*="youtube.com/"]::attr(href)')
    youtu_be = D([]).css_all('a[href*="youtu.be/"]::attr(href)')
```

### Combine schemas

Some schemas can be combined to generate a more complex data structure:

```python
from ssc_codegen import AccUniqueListSchema, ItemSchema, D, N


class Videos(AccUniqueListSchema):
    tiktok = D([]).css_all('a[href*="tiktok.com/"]::attr(href)')
    youtube = D([]).css_all('a[href*="youtube.com/"]::attr(href)')
    youtu_be = D([]).css_all('a[href*="youtu.be/"]::attr(href)')


class Header(ItemSchema):
    title = D().css("title::text")
    styles = D().css_all('link[rel="stylesheet"][href]::attr(href)')


class Main(ItemSchema):
    header = N().sub_parser(Header)
    videos = N().sub_parser(Videos)
```

returns signature like:

```
{
    "header": {"title": str, "styles": list[str]},
    "videos": list[str]
}
```

### Json parse

raw json maybe contains in script tags or elements like script[type="ld/json"]

> !note
> This feature designed for parse json strings from html pages, **not from rest-api responses**

```python
"""Example how to parse json-like data from plain HTML

Example HTML input:

<html>
    <body>
        <script type="application/json">{"a": ["b", "c"], "class": {"e": 1, "f": {"t": "pi", "v": 3.14}}, "items": [{"o": 1, "p": "ok"}, {"o": None, "p": "err"}]}</script>
    </body>
</html>
"""
from ssc_codegen import Json, D, ItemSchema


class Item(Json):
    # mark if required use this structure as start entrypoint
    __IS_ARRAY__ = True

    # mark optionals
    o: int | None
    p: str

class FItem(Json):
    t: str
    v: float

class ClassItem(Json):
    e: int
    f: FItem

class Jsn(Json):
    # remapper keys, if structure contains bad literals or
    __KEY_MAPPING__ = {
        "class_": "class"
    }
    a: list[str]
    class_: ClassItem

class Main(ItemSchema):
    """Demo structure how to parse json from html page with next structure:

    {"a": ["b", "c"], "class": {"e": 1, "f": {"t": "pi", "v": 3.14}}, "items": [{"o": 1, "p": "ok"}, {"o": None, "p": "err"}]}

    """
    data = D().css('script[type="application/json"]::text').jsonify(Jsn)

    # you can provide start query enrtypoint, if you don't need to extract the full json object
    items = D().css('script[type="application/json"]::text').jsonify(Jsn, "items")

    # extract ["class"]["f"] item
    class_f = D().css('script[type="application/json"]::text').jsonify(Jsn, "class.f")

    # extract first element
    first_item = D().css('script[type="application/json"]::text').jsonify(Jsn, "items.0")
```

Supported annotations as in standard json

| python type   | json type       |
| ------------- | --------------- |
| str           | String          |
| int           | Integer         |
| float         | Float           |
| None          | null            |
| str \| None   | String \| null  |
| int \| None   | Integer \| null |
| float \| None | Float \| null   |
| Json          | Map (dict)      |
| list\[str]    | Array\<String>  |
| list\[int]    | Array\<Integer> |
| list\[float]  | Array\<Float>   |
| list\[Json]   | Array\<Map>     |

Json structure must be consistent.

- not allowed to describe an array with random data types
- not allowed map/dicts with random keys

### Magic fields

#### `__PRE_VALIDATE__`

Optional field used for pre-validation document input. Do not modify document

```python
from ssc_codegen import ItemSchema, D


class HelloWorld(ItemSchema):
    # 1. check exists <title> tag
    # 2. check contains substring "Example" in <title> text
    # If any checks failed - throw exception
    __PRE_VALIDATE__ = D().is_css("title").css("title::text").is_contains("Example")

    title = D().css('title').text()
    a_hrefs = D().css_all('a').attr('href')
```

#### `__SPLIT_DOC__`

Special required field write how to part doucment to elements
Used in `ListSchema`, `DictSchema`, `FlatListSchema`

#### `__ITEM__`

Special required field for `FlatListSchema`

#### `__KEY__`, `__VALUE__`

Special required fields for `DictSchema`.

`__KEY__` should be returs `STRING` type

#### `__SIGNATURE__`

Optional field for configuration docstring signature generation/

## Type check system

The fields have a type check to ensure that they are converted to code correctly during the transpilation phase

### DOCUMENT

Always first type, for selector operations

### LIST_DOCUMENT

Extracted collection of elements

### STRING

Extracted text/attr/raw tag (html outher) from DOCUMENT type

### LIST_STRING

Extracted text/attr/raw tag (html outher) from LIST_DOCUMENT type

### OPTIONAL_T, default wrapper marks

If in field default value == None - last type will be casted to `Optional[T]` type

`OPTIONAL_STRING, OPTIONAL_LIST_STRING, OPTIONAL_INT, OPTIONAL_LIST_INT, OPTIONAL_FLOAT, OPTIONAL_LIST_FLOAT`

## NESTED

Special type, marks nested schema

## JSON

Special type, marks serialized json structure

## Expressions

### Cast types,

#### `to_bool()`

cast field value to boolean

value returns `false` if value is:

- None/null
- empty sequence/array
- empty string

other - `true`

```python
D().css("title").to_bool() # true
# special write wrong tag name
D().css("abbbc").to_bool() # false
D().css_all("abbbc::text").to_bool()  # false
```

#### INT, FLOAT, LIST_INT, LIST_FLOAT

cast to integers or float

- integer as int64 type
- float as float64 type

> !note
> these methods do not validate strings/input strings and they may cause a side effect.

```python
# single int
D().raw().re(r"\d+").to_int()
# array of ints
D().raw().re_all(r"\d+").to_int()

# single float
D().raw().re(r"\d+\.\d+").to_float()
# array of ints
D().raw().re_all(r"\d+").to_float()

# TIP: you can sanitaize input or validate it

# sanitaize by regex
D().css("p::text").re_sub(r"\D").to_int()

# or validate
# throw error if not matched result
D().css("p::text").is_re(r"\d+").to_int()

# or set default value
# set `0` if check failed
D(0).css("p::text").is_re(r"\d+").to_int()
```

### Default value

Set default value if check not be passed or expression throw exception

- default expr always should be a first
- this expr only catpure expression, not validate it

```python

# long variant and short variant aliases
D().default(None) == D(None)
D().default(None).raw() == R(None)

# Not support with `NESTED` and `JSON` types
# ERROR: not allowed
D(None).css(".json-tag").jsonify(JsonItem)
N(None).sub_parser(Item)

# set None/null
D(None).css("abb::text").to_int()
D(None).css("abb::text").to_float()
D(None).css("abb::text").repl("abc", "def")

# set empty array
D([]).css_all("abb::text").join(" ")
D([]).css_all("abb::text").to_int()
D([]).css_all("abb::attr(href)").to_float()

# ERROR: wrong type
D([]).css("abb::text").join(" ")
D([]).css("abb::text").to_int()
D([]).css("abb::text").to_float()
D([]).css("abb::text").to_bool()

# string default
D("example.com").css("a[href]::attr(href)").trim("http://")
# ERROR: wrong type
D("").css("abb::text").to_int()
D("").css("abb::text").to_float()
D("").css("abb::text").to_bool()


# int default
D(0).css("p::text").to_int()
# ERROR: wrong type
D(0).css("abb::text").trim(" ")
D(0).css("abb::text").to_float()
D(0).css("abb::text").to_bool()

# float default

# SPECIFY float EXPLICITLY:
# in ssc-gen, `0` not same as `0.0` or `.0`
D(.0).css("p::text").to_float()
# ERROR: wrong type
D(.0).css("abb::text").trim(" ")
D(.0).css("abb::text").to_float()
D(.0).css("abb::text").to_bool()
```

### Selectors

#### Xpath selectors limitations

If target lib not support xpath - ssc-gen throw error and not transpile to code

#### CSS selectors limitations

ssc-gen support both CSS3 and CSS4 standart validation

Recommended to use the CSS3 standard for the following reasons:

- supported by most html parsing libraries
- guaranteed to be converted to valid XPATH

If your project uses a technology (javascript) or a library that supports this standard (bs4, selectolax.lexbor), then you can describe selectors using the CSS4 standard.

Sometimes it happens that some libraries don't even support the full CSS3 standard.

For example, in [dart:html](https://dart.dev/libraries/dart-html) the CSS3 standard is not fully implemented (pseudoselectors and attribute selectors are missing).

```python
# transpiler check query syntax
# ERROR: wrong css query syntax
D().css("#123invalid-id")
D().css("div..class")
D().css("ul > > li")

# ERROR: wrong xpath query syntax
D().xpath("//div[@class='example'")
D().xpath("/bookstore/book[price>35")
D().xpath('//[@id="main"]')

# usage
# get first founded tag
D().css("title")
D().xpath("//title")
# get all founded tags
D().css_all("p")
D().xpath_all("//p")
```

### Remove element nodes

Deletes an element from a document with all child elements

This expr was added to optimize the document size (by removing "unnecessary" tags like `<svg>, <script>`, ...) for further regex searches.

> !warning
> have SIDE EFFECT, modify input doucument wout create new copy

```python
from ssc_codegen import ItemSchema, D


class Main(ItemSchema):
    hrefs = D().css_remove("head").css("a[href]::attr(href)")
    # SIDE EFFECT WARNING
    # <head> element will be removed in prev field
    # always value Main.title == "Gotcha!"
    title = D("Gotcha!").css("title::text")
```

```python
D().css_remove("head,svg,script").raw().re(...)
D().xpath_remove("//head | //svg | //script").raw().re(...)
```

### Extract element(s) data

#### raw

```python
# get full raw element (simual as `outerHTML` property from javascript)
D().raw()
# short alias
R()

# raw selected element

# CSS
D().css("div").raw()
D().css_all("div").raw()

# pseudo selector alias `::raw`
D().css("div::raw")
D().css_all("div::raw")

# XPATH
D().xpath("//div").raw()
D().xpath_all("//div").raw()

# pseudo selector alias `/raw()`
D().xpath("//div/raw()")
D().xpath_all("//div/raw()")
```

#### text

> [!note]
> ssc-gen exclude feautures like wrap/unwrap elements

```python
# CSS
D().css("p").text()
D().css_all("p").text()

# pseudo selector alias `::text`
D().css("p::text")
D().css_all("p::text")

# XPATH
D().xpath("//p").text()
D().xpath_all("p").text()

# pseudo selector alias `/text()`
D().css("//p/text()")
D().css_all("//p/text()")
```

#### attr

```python

# CSS
D().css("a").attr("href")
# if key not exists - throw error
D().css("a").attr("foobar")

# allow extract multiple attrs key
# returns flatten list of all values
D().css("a").attr("href", "class")
# if key not founded - skip wout throw error
# returns empty array
D().css("a").attr("foobar","foobaz")

# works with css_all too
D().css_all("a").attr("href")
D().css_all("a").attr("href", "class")

# have pseudoselector alias:
D().css("a::attr(href)")
D().css("a::attr(href,class)")
D().css_all("a::attr(href)")
D().css_all("a::attr(href,class)")

# xpath example
D().xpath("//a").attr("href")
D().xpath("//ab").attr("href")
D().xpath("//a").attr("href", "class")
D().xpath("//ab").attr("href", "class")

D().xpath_all("//a").attr("href")
D().xpath_all("//ab").attr("href")
D().xpath_all("//a").attr("href", "class")
D().xpath_all("//ab").attr("href", "class")

# pseudo selector alias: @(attr), @(attr1, attr2, ...)
D().xpath("//a/@(href)")
D().xpath("//a/@(href,class)")
D().xpath_all("//a/@(href,class)")
```

#### attrs_map

An expr for extracting all values from founded elements

```python
# maybe founded interesing by exracting values from custom attributes
D().css("a").attrs_map()
D().css_all("a").attrs_map()

D().xpath("//a").attrs_map()
D().xpath_all("//a").attrs_map()
```

### String operations

The basic minimum operations for converting the results.

#### trim, ltrim, rtrim

remove passed chars

- trim remove passed chars LEFT and RIGHT
- rtrim remove passed chars RIGHT
- ltrim remove passed chars LEFT

```python
# CSS
D().css("p::text").trim()
D().css("p::text").ltrim()
D().css("p::text").rtrim()

D().css_all("p::text").trim()
D().css_all("p::text").ltrim()
D().css_all("p::text").rtrim()

# XPATH
D().xpath("//p/text()").trim()
D().xpath("//p/text()").ltrim()
D().xpath("//p/text()").rtrim()

D().xpath_all("//p/text()").trim()
D().xpath_all("//p/text()").ltrim()
D().xpath_all("//p/text()").rtrim()
```

#### rm_prefix, rm_suffix, rm_prefix_suffix

remove substring prefix or suffing

```python

# CSS
D().css("p::text").rm_prefix("http")
D().css("p::text").rm_suffix("/")
D().css("p::text").rm_prefix_suffix(" ")

D().css_all("p::text").rm_prefix("http")
D().css_all("p::text").rm_suffix("/")
D().css_all("p::text").rm_prefix_suffix(" ")

# XPATH
D().xpath("//p/text()").rm_prefix("http")
D().xpath("//p/text()").rm_suffix("/")
D().xpath("//p/text()").rm_prefix_suffix(" ")

D().xpath_all("//p/text()").rm_prefix("http")
D().xpath_all("//p/text()").rm_suffix("/")
D().xpath_all("//p/text()").rm_prefix_suffix(" ")
```

#### split

split text to parts substrings

```python
# CSS
D().css("p::text").split(" ")
# XPATH
D().xpath("//p/text()").split(" ")

```

#### formatting, replace strings

-

```python

# fmt expr should be have a `{}` placeholder
# CSS
D().css("a::attr(href)").fmt("https://{}")
D().css_all("a::attr(href)").fmt("https://{}")
# XPATH
D().xpath("//a/@(href)").fmt("https://{}")
D().xpath_all("//a/@(href)").fmt("https://{}")

# replace all founded substrings
# CSS
D().css("p::text").repl("old", "new")
D().css_all("p::text").repl("old", "new")
# XPATH
D().xpath("//p/text()").repl("old", "new")
D().xpath_all("//p/text()").repl("old", "new")

# Optimized repl variant
# if you need to replace only substrings
REPLS = {"foo": "bar", "baz": "zaz"}
# CSS
D().css("p::text").repl_map(REPLS)
D().css_all("p::text").repl_map(REPLS)
# XPATH
D().xpath("//p/text()").repl_map(REPLS)
D().xpath_all("//p/text()").repl_map(REPLS)

# special function, try unescape string
# it can be used to prepare a string for `jsonify` or decode a string.
# CSS
D().css('script[type="application/json"]::text'.unescape()
D().css_all('script[type="application/json"]::text').unescape(REPLS)
# XPATH
D().xpath("//p/text()").unescape()
D().xpath_all("//p/text()").unescape()
```

#### regex

##### limitations

ssc-gen has the following limitations:

1. capture only one group (re, re_all)

```python

# ERROR: missing capture group
R().re(r"\d+")
R().re_all(r"\d+")

# ERROR: not allowed capture 2 groups
R().re(r"(some group.*) (\d+)")
# you can set non required group as non-capture
R().re(r"(?:some group.*) (\d+)")  # OK


# OK, regex sub dont need it
R().re_sub(r"\d+")
R().re_sub(r"(\d+)")
R().re_sub(r"(\d+) (foobar)")
```

2. supports next flags `re.I | re.IGNORECASE`, `re.X | re.VERBOSE`, `re.S | re.DOTALL`\*

\*some programming languages or standarts may not support the `re.S` flag.
For example, javascript ES6 standart do not support DOTALL (S) mode.

3. `re.X | re.VERBOSE` flag of the regular expression transpiles to the regular one.
   This project is designed to conveniently support parsers, so this functionality has been added.

```python
import re

P = re.compile(
    r"""
    /\*         # start comment block (/*)
    (.*?)       # content
    \*/         # END (*/)
    """, re.X | re.S)

# ssc-gen prev pattern convert to:
# P = re.compile(r'/\*(.*?)\*/', re.S)

P2 = re.compile(
    r"""
    (?:[a-zA-Z])   # some diffucult pattern group
    (
    # spam... eggs foobar
        spam...s
        | eg[gs]
        | foo(?:bar|baz)
    )
    """, re.X | re.I | re.S
)
# will be converted to
# P2 = re.compile(r"(?:[a-zA-Z])(spam...s|eg[gs]|foo(?:bar|baz))", re.I | re.S)
```

4. "complex" patterns can significantly affect the performance of the parser as [catastrophic backtracking](https://regex101.com/r/iXSKTs/1/debugger)

Usage:

```python
D().css("p::text").re(r"(\d+)")

# support pass compiled regex pattern:
RE_DIGIT = re.compile(r"(\d+)")
D().css("p::text").re(RE_DIGIT)

D().css("p::text").re_all(r"(\d+)")
D().css("p::text").re_all(RE_DIGIT)

# ERROR: not works with LIST_STRING type
D().css_all("p::text").re(RE_DIGIT)
D().css_all("p::text").re_all(RE_DIGIT)

# You don't have to specify capturing groups.
D().css("p::text").re_sub(r"\d+", "<INT>"),
D().css_all("p::text").re_sub(r"\d+", "<INT>"),

# generate template as ^<start pattern>, <end pattern>$
# re_trim(r"\s+", "") equal:
# re_sub(r"^\s+", "").(r"\s+$", "")
D().css("p::text").re_trim(r"\s+", ""),
D().css_all("p::text").re_trim(r"\s+", ""),
```

### Array-like operations

#### to_len

cast any array-like object to length

```python
D().css_all("a").to_len()
D().xpath_all("a").to_len()
D().xpath_all("a::attr(href)").to_len()
D().css("p::text").re_all(r"\d+").to_len()
```

#### index operations

> [!note] Use pseudo-selectors in the selection of elements.
> It is recommended to extract the necessary elements using the pseudo-selector [:nth-child()](https://developer.mozilla.org/docs/Web/CSS/:nth-child)

```python
# get second product url from `https://books.toscrape.com/`


# recommended use :nth-child()
D().css(".col-lg-3:nth-child(2) .image_container > a::attr(href)")

# same, but not recommended
D().css_all(".col-lg-3 .image_container > a::attr(href)").index(1)

# get first element (alias index(0))
D().css_all("a::text").first()
# get last element (alias index(-1))
D().css_all("a::text").last()
```

#### join()

```python
# join all sequence of strings to one

D().css_all("p::text").join(" ")
D().cssl("p::text").split(" ").join("\n")
```

#### filters

`unique()`

```python
# drop duplicates from sequence of string
# ELEMENTS ORDER NOT BE GUARANTEED

# drop duplicated in extracted href values
D().css_all("a::attr(href)").unique()
# drop duplicated words
D().css("p::text").split(" ").unique()
```

`filter()`

filter LIST_STRING collection by rule.

supports next logic operators

| op   | description |
| ---- | ----------- |
| `&`  | logical AND |
| `\|` | logical OR  |
| `~`  | logical NOT |

syntax cheat sheet

- `op` - filter syntax
- `code equal` - equivalent pseudocode
  - the examples are written in an imperative style, if the language supports higher-order functions (eg: python `any()`, `all()`), then they will be given in them
  - `i` - abstract element in the collection to be filtered

| Expression               | Equivalent Code                          | Description                        |
| ------------------------ | ---------------------------------------- | ---------------------------------- |
| `F() == "A"`             | `i == "A"`                               | str equal                          |
| `F() == ("A", "B")`      | `i == "A" or i == "B"`                   | any str equal collection           |
| `F() != "A"`             | `i != "A"`                               | str not equal                      |
| `F() != ("A", "B")`      | `i != "A" and i != "B"`                  | all str not equal collection       |
| `F().re(r"\d+")`         | `regex.search(r"\d+", i) is not None`    | regex match by pattern             |
| `F().contains("a")`      | `"a" in i`                               | substr contains                    |
| `F().contains("a", "b")` | `"a" in i or "b" in i`                   | any str contains                   |
| `F().starts("a")`        | `i.startswith("a")`                      | substr starts in str               |
| `F().starts("a", "b")`   | `i.startswith("a") or i.startswith("b")` | any substr starts in str           |
| `F().ends("a")`          | `i.endswith("a")`                        | substr ends in str                 |
| `F().ends("a", "b")`     | `i.endswith("a") or i.endswith("b")`     | any substr ends in str             |
| `F() > 10`               | `len(i) > 10`                            | str is longer than value           |
| `F() >= 10`              | `len(i) >= 10`                           | str is longer or equal than value  |
| `F() < 10`               | `len(i) < 10`                            | str is shorter than value          |
| `F() <= 10`              | `len(i) <= 10`                           | str is shorter or equal than value |

Usage example

```python
from ssc_codegen import D, F

shortcuts wrap to brackets:

# ERROR
F() == ("A", "B") & F() < 10
# OK
(F() == ("A", "B")) & (F < 10)

F_URL_LIKE = F().starts("http")
# combines filers

# NOT ("John" in i AND "Doe" in i)
F_EXLUDE_STR = ~(F().contains("John", "john") & F().contains("Doe", "doe"))

# (i.startswith("email:" and "@" in i) AND len(i) < 64 AND NOT i.starts("info@")
F_EMAIL = (F().starts("email:") | F().contains("@")) & (F() < 64) & ~F().starts("info@")

# allow combine defined filters:
F_COMBINED = F_EXCLUDE_STR & F_EMAIL

# USAGE examples
D().css_all("a[href]::attr(href)").filter(F_EMAIL)
D().css_all("a[href]::attr(href)").filter(F_EXCLUDE_STR)
```

### Asserts

Optional expressions for validating data. all provided expressions does not modify value in chain calls

```python
from ssc_codegen import ItemSchema, D

class Main(ItemSchema):
    # first called before parse
    # if check not passed - throw error
    __PRE_VALIDATE__ = D().is_css("title").css("title::text").is_contains("Example Domain")

    # default value can be capture error and set default value
    # if <a> with href attribure not fouded - set empty array
    urls = D([]).is_css("a[href]").css_all("a[href]::attr(href)")
```

Examples:

```python

# test selectors
# if not founded - throw error
D().is_css("title")
D().is_xpath("//title")

# you can catch expection and set default value

# if <title> tag not exists set default value
D("Empty title").is_css("title").css_all("title::text")

# test equal values (str, int, float)
D().css("title::text").is_equal("Example Domain")
D().css("p::text").to_int().is_equal(1)

D().css("p::text").is_not_equal("Example Domain")
D().css("p::text").to_int().is_not_equal(1)

# test contains substring
D().css("title::text").is_contains("Example")

# test ANY LIST_STRING collection matched by pattern
D().css_all("p::text").any_is_re(r"\d")

# test ALL LIST_STRING collection matched by pattern
D().css_all("p::text").all_is_re(r"\d")

# test matched string by regex
D().css("p::text").is_re(r"\d")

# test contains attribute
D().css("#someid").has_attr("class")
```

### Nested Schemas

`sub_parser()`

Special method in the `N() marker` to create a more complex structure

```python
from ssc_codegen import ItemSchema, DictSchema, D, N

class Meta(DictSchema):
    __SPLIT_DOC__ = D().css_all("head > meta[name][content]")

    __KEY__ = D().attr("name")
    __VALUE__ = D().attr("content")


class Head(ItemSchema):
    # generated parser structure:
    # {
    #       title: str, styles: list[str],
    #       meta: {meta_name: meta_content, ...}
    # }
    title = D().css("title::text")
    styles = D([]).css_all('link[rel="stylesheet"][href]::attr(href)')
    meta = N().sub_parser(Meta)


class Main(ItemSchema):
    # generated parser structure:
    # {
    # head:
    #   {
    #       title: str, styles: list[str],
    #       meta: {meta_name: meta_content, ...}
    #   },
    # urls: list[str]
    # }
    head = N().sub_parser(Head)
    urls = D([]).css_all("a[href]::attr(href)")
```

- you can reuse generated classes: They all work independently of each other
- or call `Main` class and parse all

`jsonify()`

Special method for serializing json string from html document

first argument accept `Json` markered class, second - optional json path

json path syntax:

| expression    | description                                        |
| ------------- | -------------------------------------------------- |
| `"key"`       | extract data from `["key"]` and serialize          |
| `"key1.key2"` | extract data from `["key1"]["key2"]` and serialize |
| `"key.0"`     | extract data from `["key"][0]` and serialize       |

Usage example:

```python
"""
<!-- example json-like structure in HTML document -->
<script type="application/json">
    {"a": ["b", "c"], "class": {"e": 1, "f": {"t": "pi", "v": 3.14}}, "items": [{"o": 1, "p": "ok"}, {"o": None, "p": "err"}]}
</script>
"""
from ssc_codegen import Json, D, ItemSchema


class Item(Json):
    # mark if required use this structure as start entrypoint
    __IS_ARRAY__ = True

    # mark optional
    o: int | None
    p: str

class FItem(Json):
    t: str
    v: float

class ClassItem(Json):
    e: int
    f: FItem

class Jsn(Json):
    # remapper keys, if structure contains bad literals or
    __KEY_MAPPING__ = {
        "class_": "class"
    }
    a: list[str]
    class_: ClassItem

JSN_SELECTOR = 'script[type="application/json"]::text'

class Main(ItemSchema):
    """Demo structure how to parse json from html page with next structure:

    {"a": ["b", "c"], "class": {"e": 1, "f": {"t": "pi", "v": 3.14}}, "items": [{"o": 1, "p": "ok"}, {"o": None, "p": "err"}]}

    """
    data = D().css(JSN_SELECTOR).jsonify(Jsn)

    # you can provide start query enrtypoint, if you don't need to extract the full json object
    items = D().css(JSN_SELECTOR).jsonify(Jsn, "items")

    # extract ["class"]["f"] item
    class_f = D().css(JSN_SELECTOR).jsonify(Jsn, "class.f")

    # extract first element
    first_item = D().css(JSN_SELECTOR).jsonify(Jsn, "items.0")
```

## tips and tricks

### selectors

#### define complex selectors/regexes as constant

Just for easier reading of the code.

```python
# syntetic examples
CSS4_SELECTOR_TEXT = (
    "div.card.highlighted" 
    " > h2.title:is(.main, .featured) 
    "+ p.summary:not(.hidden)"
    "::text"
)
REGEX_PATTERN = re.compile(r"""
    \b                  # START word
    ([a-z0-9._%+-]+)    # Имя username
    @
    ([a-z0-9.-]+)       # domain
    \.
    ([a-z]{2,})         # top domain
    \b                  # END
""", re.X | re.I)

# Usage
D().css(CSS4_SELECTOR_TEXT).re(REGEX_PATTERN)


```

#### extracting multiple values from attributes

If you need to extract a lot of attributes, for example, the URL or patches, you can use the following selector:

```python
# TIP: you can define selector as constant
# CSS3
SEL_CSS3 = "[href],[src],[formaction]::attr(href,src,formaction)"
# CSS4
SEL_CSS4 = "*:is([href], [src], [formaction])::attr(href,src,formaction)"
# XPATH
SEL_XPATH = "//*[@href or @src or @formaction]/@(href,src,formaction)"

D().css_all(SEL_CSS3)
D().css_all(SEL_CSS4)
D().xpath_all(SEL_CSS4)
```

### factories

This project uses __a real cpython__, so you can simplify some template actions!

#### helper functions


```python
from ssc_codegen import ItemSchema, D
# example css generator extractor
DEFALUT_ATTRS = ("src", "href", "onclick")
def css_attr_substr(substr: str, attrs: tuple[str]=DEFALUT_ATTRS) -> str:
    """
    css_attr_substr("spam") -> [src*="spam",href*="spam",onclick*="spam"]::attr(src,href,onclick) 
    
    """
    selector = ",".join[f'[{a}*="{substr}"]' for a in attrs]
    return selector + "::attr(" + ','.join(attrs) + ")"

def D_SOC(substr: str) -> str:
    return D([]).css(css_attr_substr(substr))

# usage:

class SocialExtractor(ItemShema):
    github = D_SOC("github.com/")
    gitlab = D_SOC("gitlab.com/")
    youtube = D_SOC("youtube.com/")
    # add other socials...
```

#### schemas factory

Unfortunately, to create schemas factories, you will have to resort **to the black magic of metaprogramming**.


```python
from typing import Type
from urllib.parse import urlsplit
import re

from ssc_codegen import ItemSchema, D


def css_attr_substr(substr: str, attrs: tuple[str]=DEFALUT_ATTRS) -> str:
    """
    css_attr_substr("spam") -> [src*="spam",href*="spam",onclick*="spam"]::attr(src,href,onclick) 
    
    """
    selector = ",".join[f'[{a}*="{substr}"]' for a in attrs]
    return selector + "::attr(" + ','.join(attrs) + ")"

def D_SOC(substr: str) -> str:
    return D([]).css(css_attr_substr(substr))


def schema_socials_factory(*domains: str) -> Type[ItemSchema]:
    class_dict = {}
    for d in domains:
        name = urlsplit(d).netloc
        # fix corner case if domain starts digit char
        name = "f" + urlsplit(d).netloc if d[0].isdigit() else name
        class_dict[name] = D_SOC(d)
    # or other logic create class name
    class_name = "SocialParser"
    # create new schema instance:
    return type(class_name, (ItemSchema,), class_dict) 


# ssc-gen capture this class and convert it to code
SocialParser = schema_socials_factory(
    "github.com/",
    "gitlab.com/",
    "youtube.com/",
    # add other socials ...
    )
```
